name: ai-client

networks:
  ai_net:
    external: true
  proxy:
    external: true

services:
  openwebui:
    image: ghcr.io/open-webui/open-webui:latest
    container_name: openwebui
    restart: unless-stopped
    environment:
      - TZ=America/Sao_Paulo
      - OLLAMA_BASE_URL=http://ollama:11434
    volumes:
      - /srv/ai/openwebui/data:/app/backend/data:rw
    networks: [ai_net, proxy]
    labels:
      - com.centurylinklabs.watchtower.enable=true

  n8n:
    image: docker.n8n.io/n8nio/n8n:latest
    container_name: n8n
    restart: unless-stopped
    environment:
      - TZ=America/Sao_Paulo
      - N8N_HOST=${N8N_HOST:-n8n.local}
      - N8N_PROTOCOL=https
      - N8N_PORT=5678
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY:-change-me}
      - GENERIC_TIMEZONE=${TZ}
    volumes:
      - /srv/ai/n8n:/home/node/.n8n:rw
    networks: [proxy]
    labels:
      - com.centurylinklabs.watchtower.enable=true

  mcp-gateway:
    image: docker/mcp-gateway:latest
    container_name: mcp-gateway
    restart: unless-stopped
    # Transport "streaming" expõe HTTP/WS para vários clientes
    command:
      - --transport=streaming
      - --port=8811
      # Habilite servidores MCP do catálogo (exemplos abaixo). Adicione/remova conforme precisar:
      - --servers=duckduckgo
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:rw
    ports:
      - "8811:8811"
    networks: [ai_net, proxy]
    labels:
      - com.centurylinklabs.watchtower.enable=true
